{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multivariate Linear Regression.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6HQBNPdGp/O/cLjZokgV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinlee192/AI-basic/blob/master/Multivariate_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DrXRwg_F8S6t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Data representation"
      ],
      "metadata": {
        "id": "aduRqtTcMFka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1) #랜덤함수를 고정시킴\n",
        "torch.rand(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3qSPB5H8jnA",
        "outputId": "80fa30eb-1af7-443e-e1fa-ce4b3c449909"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "jdPm8cYVIonC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 초기화\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True) \n",
        "\n",
        "# requires_grad 가 무엇인지\n",
        "# => 학습할 데이터라고 명시하는 것\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer = optim.SGD([w1,w2,w3,b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    #H(x) 계산\n",
        "    hypothesis = x1_train*w1 + x2_train*w2 + x3_train*w3 + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "    # cost로 H(x) 개선, 항상 붙어다니는 3줄\n",
        "    optimizer.zero_grad()   # Gradient 초기화\n",
        "    cost.backward()         # Gradient 계산\n",
        "    optimizer.step()        # Wegit, bias 개선\n",
        "\n",
        "    #error = y - x @ beta\n",
        "    #grad = -transpose(X) @ error\n",
        "    #beta = beta - lr*grad\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #100번 마다 로그 출력\n",
        "    if epoch % 100 == 0 :\n",
        "        print('Epoch {:4d}/{} w1 : {:.3f} w2 : {:.3f} w3 : {:.3f} b: {:.3f} Cost : {:.6f}'.format(epoch, nb_epochs, w1.item(),w2.item(),w3.item(),b.item(), cost.item() ))\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F58xOyFKIoNq",
        "outputId": "b1963cb6-630e-4bad-f385-d4e00420804f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1 : 0.294 w2 : 0.294 w3 : 0.297 b: 0.003 Cost : 29661.800781\n",
            "Epoch  100/1000 w1 : 0.674 w2 : 0.661 w3 : 0.676 b: 0.008 Cost : 1.563628\n",
            "Epoch  200/1000 w1 : 0.679 w2 : 0.655 w3 : 0.677 b: 0.008 Cost : 1.497595\n",
            "Epoch  300/1000 w1 : 0.684 w2 : 0.649 w3 : 0.677 b: 0.008 Cost : 1.435044\n",
            "Epoch  400/1000 w1 : 0.689 w2 : 0.643 w3 : 0.678 b: 0.008 Cost : 1.375726\n",
            "Epoch  500/1000 w1 : 0.694 w2 : 0.638 w3 : 0.678 b: 0.009 Cost : 1.319507\n",
            "Epoch  600/1000 w1 : 0.699 w2 : 0.633 w3 : 0.679 b: 0.009 Cost : 1.266222\n",
            "Epoch  700/1000 w1 : 0.704 w2 : 0.627 w3 : 0.679 b: 0.009 Cost : 1.215703\n",
            "Epoch  800/1000 w1 : 0.709 w2 : 0.622 w3 : 0.679 b: 0.009 Cost : 1.167810\n",
            "Epoch  900/1000 w1 : 0.713 w2 : 0.617 w3 : 0.680 b: 0.009 Cost : 1.122429\n",
            "Epoch 1000/1000 w1 : 0.718 w2 : 0.613 w3 : 0.680 b: 0.009 Cost : 1.079390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Data Represenstation\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "x_1 & x_2 & x_3\n",
        "\\end{pmatrix}\n",
        "\\cdot\n",
        "\\begin{pmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "x_1w_1 + x_2w_2 + x_3w_3\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "BXQEYhr6MbGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ H(X) = XW $$"
      ],
      "metadata": {
        "id": "0mwPTYuuMxXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "M0QjSZAgKsFL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train, x_train.shape)\n",
        "print(y_train, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZnrsSk5M4lQ",
        "outputId": "489f821f-8404-4520-bc82-61f316f22a42"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  80.,  75.],\n",
            "        [ 93.,  88.,  93.],\n",
            "        [ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]) torch.Size([5, 3])\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]]) torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 초기화\n",
        "W = torch.zeros((3,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000\n",
        "\n",
        "for epoch in range(nb_epochs + 1) :\n",
        "    #H(x)\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    #Cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "    #cost로 H(X) 개선 gradient decent\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch %100 == 0 : \n",
        "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp4A5_b_NI9Y",
        "outputId": "7fc56a0d-cae6-4524-f1b6-1acadc3610b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch  100/1000 hypothesis: tensor([152.7691, 183.6985, 180.9591, 197.0627, 140.1336]) Cost: 1.563628\n",
            "Epoch  200/1000 hypothesis: tensor([152.7273, 183.7273, 180.9465, 197.0517, 140.1731]) Cost: 1.497595\n",
            "Epoch  300/1000 hypothesis: tensor([152.6866, 183.7554, 180.9343, 197.0409, 140.2116]) Cost: 1.435044\n",
            "Epoch  400/1000 hypothesis: tensor([152.6470, 183.7827, 180.9224, 197.0304, 140.2491]) Cost: 1.375726\n",
            "Epoch  500/1000 hypothesis: tensor([152.6085, 183.8093, 180.9108, 197.0201, 140.2856]) Cost: 1.319507\n",
            "Epoch  600/1000 hypothesis: tensor([152.5711, 183.8352, 180.8996, 197.0101, 140.3211]) Cost: 1.266222\n",
            "Epoch  700/1000 hypothesis: tensor([152.5346, 183.8604, 180.8887, 197.0003, 140.3557]) Cost: 1.215703\n",
            "Epoch  800/1000 hypothesis: tensor([152.4992, 183.8849, 180.8780, 196.9908, 140.3895]) Cost: 1.167810\n",
            "Epoch  900/1000 hypothesis: tensor([152.4647, 183.9087, 180.8677, 196.9814, 140.4223]) Cost: 1.122429\n",
            "Epoch 1000/1000 hypothesis: tensor([152.4312, 183.9319, 180.8577, 196.9723, 140.4543]) Cost: 1.079390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-level Implementation with `nn.Module`"
      ],
      "metadata": {
        "id": "yySx4UmriLaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self) :\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1,1)  # x input 1,1 dim\n",
        "\n",
        "    def forward(self, x) :\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "YIXHEGvXiPk3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예제 사용을 위해 이름만 바꿔서 다시 정의, dim 1->3\n",
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "    def __init__(self) :\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3,1)  # x input 3,1 dim\n",
        "\n",
        "    def forward(self, x) :\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "qkbs0ymij9xI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 모델 초기화\n",
        "model = MultivariateLinearRegressionModel() # 위에 만들었던 클레스\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5) #optimizer = optim.SGD([W,b], lr=1e-5)\n",
        "\n",
        "#print(model.parameters())\n",
        "# W,b 를 넣어줄 필요가 없어짐, nn.Module 상속한 클래스 통해서 자연스럽게 들어가는듯\n",
        "\n",
        "nb_epoch = 20\n",
        "\n",
        "for epoch in range(nb_epoch +1):\n",
        "    #H(x)\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    #cost 계산 torch.nn.functional의 mse 손실함수 사용\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    #cost로 H(X) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epoch, cost.item()\n",
        "        ))\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yncA1_dVjt8n",
        "outputId": "045a5155-3a1d-44f6-9659-cf055e407b60"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Cost: 30431.457031\n",
            "Epoch    1/20 Cost: 9540.133789\n",
            "Epoch    2/20 Cost: 2991.811768\n",
            "Epoch    3/20 Cost: 939.261719\n",
            "Epoch    4/20 Cost: 295.894836\n",
            "Epoch    5/20 Cost: 94.233376\n",
            "Epoch    6/20 Cost: 31.022274\n",
            "Epoch    7/20 Cost: 11.208364\n",
            "Epoch    8/20 Cost: 4.997212\n",
            "Epoch    9/20 Cost: 3.049662\n",
            "Epoch   10/20 Cost: 2.438606\n",
            "Epoch   11/20 Cost: 2.246437\n",
            "Epoch   12/20 Cost: 2.185588\n",
            "Epoch   13/20 Cost: 2.165900\n",
            "Epoch   14/20 Cost: 2.159098\n",
            "Epoch   15/20 Cost: 2.156359\n",
            "Epoch   16/20 Cost: 2.154869\n",
            "Epoch   17/20 Cost: 2.153797\n",
            "Epoch   18/20 Cost: 2.152813\n",
            "Epoch   19/20 Cost: 2.151920\n",
            "Epoch   20/20 Cost: 2.151002\n"
          ]
        }
      ]
    }
  ]
}