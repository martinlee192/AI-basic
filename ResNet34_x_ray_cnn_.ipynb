{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet34 x-ray cnn .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODjEzb/iqkc8milzzEVeHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinlee192/AI-basic/blob/master/ResNet34_x_ray_cnn_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlY3o6AFHqEO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI3Wx2muUl8Z",
        "outputId": "a832574b-5deb-469a-8e90-058d8edd57c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!dir /gdrive/MyDrive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DUohEQNUpRL",
        "outputId": "9174de4c-d045-4b91-8831-194774c3ae94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "model_simple_layer_20epoch.pth\tx_ray_test_data      x_ray_train_data\n",
            "model_vgg16_50epoch.pth\t\tx_ray_test_data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nomalization 값 구해서 넣기!!!!!!!!!\n",
        "trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "     ])\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(root='/gdrive/MyDrive/data/x_ray_train_data', transform=trans)"
      ],
      "metadata": {
        "id": "Gv49WpWsUwxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in trainset]\n",
        "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in trainset]\n",
        "\n",
        "meanR = np.mean([m[0] for m in meanRGB])\n",
        "meanG = np.mean([m[1] for m in meanRGB])\n",
        "meanB = np.mean([m[2] for m in meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in stdRGB])\n",
        "stdG = np.mean([s[1] for s in stdRGB])\n",
        "stdB = np.mean([s[2] for s in stdRGB])\n",
        "\n",
        "print(meanR, meanG, meanB)\n",
        "print(stdR, stdG, stdB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTKTBCVcgisc",
        "outputId": "9abf0a45-a5f3-40f7-a7f1-d83c6c0489b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.48235524 0.48235524 0.48235524\n",
            "0.22150697 0.22150697 0.22150697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "캐글에서 다른 사람의 경우\n",
        "[0.485, 0.456, 0.406] , [0.229,0.224,0.225] 사용\n",
        "\n",
        "resnet50 예시\n",
        "https://www.kaggle.com/code/teyang/pneumonia-detection-resnets-pytorch/notebook\n",
        "\n",
        "resnet34 도 있다\n",
        "https://www.kaggle.com/code/vishnurapps/identifying-pneumonia-from-xrays-using-resnet"
      ],
      "metadata": {
        "id": "eLdzjgFjkMG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalization 구하기 https://deep-learning-study.tistory.com/475"
      ],
      "metadata": {
        "id": "TLhZiObSh4BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],  [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],  [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(root='/gdrive/MyDrive/data/x_ray_train_data', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.ImageFolder(root='/gdrive/MyDrive/data/x_ray_test_data', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('Normal','PNEUMONIA')\n"
      ],
      "metadata": {
        "id": "AMTP-3HKWNqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#''' 이렇게 해도 된다.\n",
        "#import resnet\n",
        "#conv1x1=resnet.conv1x1\n",
        "#Bottleneck = resnet.Bottleneck\n",
        "#BasicBlock= resnet.BasicBlock\n",
        "#'''"
      ],
      "metadata": {
        "id": "13Gymewrb65i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "metadata": {
        "id": "z6QpHoTrII6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. BasicBlock for Resnet18,34\n",
        "3x3 cov, c = 64\n",
        "3x3 cov, c = 64\n",
        "'+'\n",
        "relu\n",
        "\n",
        "2. Bottleneck for Resnet 50,101,152\n",
        "1x1, 64\n",
        "3x3, 64\n",
        "1x1, 256(64*expension)\n",
        "'+' relu\n",
        "3.'+'는 이전 입력을 더해 주는 걸 뜻하며 Identity라고 단어 사용"
      ],
      "metadata": {
        "id": "2Q3XBgvwKJGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride) # 받아온 stride를 넣어줌\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)      # 따로 안넣었으니 stride =1 이다\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x) # 3x3 stride = 2\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out) # 3x3 stride = 1\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "gYr2Pb79IVEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = conv1x1(inplanes, planes) #conv1x1(64,64)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)#conv3x3(64,64)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion) #conv1x1(64,256)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x) # 1x1 stride = 1\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out) # 3x3 stride = stride \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out) # 1x1 stride = 1\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "GlAZyPMFIY5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    # model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #resnet 50 \n",
        "    def __init__(self, block, layers, num_classes=2, zero_init_residual=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        #shape = [ 3 x 224 x 224]\n",
        "        self.inplanes = 64\n",
        "             \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        #shape = [ 64 x 112 x 112] \n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        #shape = [ 64 x 112 x 112] \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        #shape = [ 64 x 56 x 56] \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])#'''3'''\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)#'''4'''\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)#'''6'''\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)#'''3'''\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "    \n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        \n",
        "        downsample = None\n",
        "        \n",
        "        if stride != 1 or self.inplanes != planes * block.expansion: \n",
        "            \n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride), #conv1x1(256, 512, 2)\n",
        "                nn.BatchNorm2d(planes * block.expansion), #batchnrom2d(512)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        \n",
        "        self.inplanes = planes * block.expansion #self.inplanes = 128 * 4\n",
        "        \n",
        "        for _ in range(1, blocks): \n",
        "            layers.append(block(self.inplanes, planes)) # * 3\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Sgmnq69xI4dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(pretrained=False, **kwargs):\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs) #=> 2*(2+2+2+2) +1(conv1) +1(fc)  = 16 +2 =resnet 18\n",
        "    return model"
      ],
      "metadata": {
        "id": "8kpFzR6nI5F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet34(pretrained= False, **kwargs):\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs) #=> 2*(3+4+6+3) +1(conv1) +1(fc) = 32 + 2 = resnet 34\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "emSnjPhmTVKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet50(pretrained=False, **kwargs):\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #=> 3*(3+4+6+3) +(conv1) +1(fc) = 48 +2 = 50\n",
        "    return model"
      ],
      "metadata": {
        "id": "eskojqKpIM3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet34 = resnet34().to(device)"
      ],
      "metadata": {
        "id": "-NyLkrfOUYLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.Tensor(1,3,224,224).to(device)\n",
        "out = model_resnet34(a)\n",
        "print(out)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjPTALCbzA06",
        "outputId": "64b694bf-2e98-4232-a004-ec57fbb86f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0177, -0.6249]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model_resnet34.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n",
        "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "6-XOhXb4zBF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define acc_check function"
      ],
      "metadata": {
        "id": "QXWJvsWt0xjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_check(net, test_set, epoch, save=0):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_set:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(images)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    acc = (100 * correct / total)\n",
        "    print('Accuracy of the network on the %d test images: %d %%' %total , acc)\n",
        "    if save:\n",
        "        torch.save(net.state_dict(), \"./model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
        "    return acc"
      ],
      "metadata": {
        "id": "oFVfLGAPzBLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainloader))\n",
        "total_batch = len(trainloader)\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    avg_cost = 0.0\n",
        "    \n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model_resnet34(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        avg_cost += loss / total_batch\n",
        "    \n",
        "    lr_sche.step()\n",
        "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
        "    if epochs%50 == 49:\n",
        "          torch.save(model_resnet34.state_dict(), \"/gdrive/MyDrive/data/Resnet34_epoch_{}.pth\".format(epoch))\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD-WNfgM1hyg",
        "outputId": "89f370b6-ca66-4ddd-d93d-af782fe26994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "522\n",
            "[Epoch:1] cost = 0.23021014034748077\n",
            "[Epoch:2] cost = 0.16510172188282013\n",
            "[Epoch:3] cost = 0.14413471519947052\n",
            "[Epoch:4] cost = 0.131316140294075\n",
            "[Epoch:5] cost = 0.1263149231672287\n",
            "[Epoch:6] cost = 0.10945085436105728\n",
            "[Epoch:7] cost = 0.11652301251888275\n",
            "[Epoch:8] cost = 0.1108417958021164\n",
            "[Epoch:9] cost = 0.1105998307466507\n",
            "[Epoch:10] cost = 0.06523022800683975\n",
            "[Epoch:11] cost = 0.06825044751167297\n",
            "[Epoch:12] cost = 0.06100349500775337\n",
            "[Epoch:13] cost = 0.06032335013151169\n",
            "[Epoch:14] cost = 0.06575620919466019\n",
            "[Epoch:15] cost = 0.061594750732183456\n",
            "[Epoch:16] cost = 0.062108442187309265\n",
            "[Epoch:17] cost = 0.0681547150015831\n",
            "[Epoch:18] cost = 0.05649698153138161\n",
            "[Epoch:19] cost = 0.06316456943750381\n",
            "[Epoch:20] cost = 0.029857849702239037\n",
            "[Epoch:21] cost = 0.01995094306766987\n",
            "[Epoch:22] cost = 0.01783050037920475\n",
            "[Epoch:23] cost = 0.02360515482723713\n",
            "[Epoch:24] cost = 0.026058875024318695\n",
            "[Epoch:25] cost = 0.026781458407640457\n",
            "[Epoch:26] cost = 0.019061468541622162\n",
            "[Epoch:27] cost = 0.033732932060956955\n",
            "[Epoch:28] cost = 0.022522728890180588\n",
            "[Epoch:29] cost = 0.02767462097108364\n",
            "[Epoch:30] cost = 0.008436199277639389\n",
            "[Epoch:31] cost = 0.002703584497794509\n",
            "[Epoch:32] cost = 0.0017689296510070562\n",
            "[Epoch:33] cost = 0.001325898221693933\n",
            "[Epoch:34] cost = 0.0011750600533559918\n",
            "[Epoch:35] cost = 0.0007741049630567431\n",
            "[Epoch:36] cost = 0.0008166713523678482\n",
            "[Epoch:37] cost = 0.0009443977032788098\n",
            "[Epoch:38] cost = 0.0006783859571442008\n",
            "[Epoch:39] cost = 0.0005169280921109021\n",
            "[Epoch:40] cost = 0.0005789442220702767\n",
            "[Epoch:41] cost = 0.0005076876259408891\n",
            "[Epoch:42] cost = 0.0005215477431192994\n",
            "[Epoch:43] cost = 0.0005921231932006776\n",
            "[Epoch:44] cost = 0.0005202727625146508\n",
            "[Epoch:45] cost = 0.0005449680611491203\n",
            "[Epoch:46] cost = 0.0027489091735333204\n",
            "[Epoch:47] cost = 0.0009895998518913984\n",
            "[Epoch:48] cost = 0.0006379885016940534\n",
            "[Epoch:49] cost = 0.0005576993571594357\n",
            "[Epoch:50] cost = 0.0006546845543198287\n",
            "[Epoch:51] cost = 0.0005902562406845391\n",
            "[Epoch:52] cost = 0.0006150096305646002\n",
            "[Epoch:53] cost = 0.0005938717513345182\n",
            "[Epoch:54] cost = 0.0009191205026581883\n",
            "[Epoch:55] cost = 0.001074819010682404\n",
            "[Epoch:56] cost = 0.0005498917307704687\n",
            "[Epoch:57] cost = 0.0007164033013395965\n",
            "[Epoch:58] cost = 0.0005834018811583519\n",
            "[Epoch:59] cost = 0.0005615719710476696\n",
            "[Epoch:60] cost = 0.000568181334529072\n",
            "[Epoch:61] cost = 0.000578539737034589\n",
            "[Epoch:62] cost = 0.0005445976858027279\n",
            "[Epoch:63] cost = 0.0005036958027631044\n",
            "[Epoch:64] cost = 0.00048597852583043277\n",
            "[Epoch:65] cost = 0.00048492179485037923\n",
            "[Epoch:66] cost = 0.0005216327263042331\n",
            "[Epoch:67] cost = 0.0005617547431029379\n",
            "[Epoch:68] cost = 0.000492726918309927\n",
            "[Epoch:69] cost = 0.0005249922978691757\n",
            "[Epoch:70] cost = 0.0005066758021712303\n",
            "[Epoch:71] cost = 0.0005234011332504451\n",
            "[Epoch:72] cost = 0.0005108972545713186\n",
            "[Epoch:73] cost = 0.0006377034587785602\n",
            "[Epoch:74] cost = 0.0006499490700662136\n",
            "[Epoch:75] cost = 0.0004893337609246373\n",
            "[Epoch:76] cost = 0.0005969233461655676\n",
            "[Epoch:77] cost = 0.0005654286942444742\n",
            "[Epoch:78] cost = 0.0005212812102399766\n",
            "[Epoch:79] cost = 0.0004680581041611731\n",
            "[Epoch:80] cost = 0.00047574733616784215\n",
            "[Epoch:81] cost = 0.0005067031015641987\n",
            "[Epoch:82] cost = 0.0005310529377311468\n",
            "[Epoch:83] cost = 0.0004914431483484805\n",
            "[Epoch:84] cost = 0.0005599327269010246\n",
            "[Epoch:85] cost = 0.0005516430828720331\n",
            "[Epoch:86] cost = 0.00080520985648036\n",
            "[Epoch:87] cost = 0.0004984227125532925\n",
            "[Epoch:88] cost = 0.0005153717938810587\n",
            "[Epoch:89] cost = 0.0005870909662917256\n",
            "[Epoch:90] cost = 0.00051697320304811\n",
            "[Epoch:91] cost = 0.0004856460145674646\n",
            "[Epoch:92] cost = 0.0007745074108242989\n",
            "[Epoch:93] cost = 0.000531814934220165\n",
            "[Epoch:94] cost = 0.0004906105459667742\n",
            "[Epoch:95] cost = 0.0005100411945022643\n",
            "[Epoch:96] cost = 0.0005154884420335293\n",
            "[Epoch:97] cost = 0.0005503128631971776\n",
            "[Epoch:98] cost = 0.0004723384918179363\n",
            "[Epoch:99] cost = 0.00048515520757064223\n",
            "[Epoch:100] cost = 0.000551427248865366\n",
            "[Epoch:101] cost = 0.0005080840783193707\n",
            "[Epoch:102] cost = 0.0005897580413147807\n",
            "[Epoch:103] cost = 0.0005464332061819732\n",
            "[Epoch:104] cost = 0.0005700227920897305\n",
            "[Epoch:105] cost = 0.0005516402889043093\n",
            "[Epoch:106] cost = 0.001125996932387352\n",
            "[Epoch:107] cost = 0.0005124983727000654\n",
            "[Epoch:108] cost = 0.0005321517819538713\n",
            "[Epoch:109] cost = 0.0005256153526715934\n",
            "[Epoch:110] cost = 0.0005068649188615382\n",
            "[Epoch:111] cost = 0.0005917676026001573\n",
            "[Epoch:112] cost = 0.00061874242965132\n",
            "[Epoch:113] cost = 0.0005290762637741864\n",
            "[Epoch:114] cost = 0.0005200302111916244\n",
            "[Epoch:115] cost = 0.0007883325451985002\n",
            "[Epoch:116] cost = 0.000538130640052259\n",
            "[Epoch:117] cost = 0.0005875317729078233\n",
            "[Epoch:118] cost = 0.0004938641213811934\n",
            "[Epoch:119] cost = 0.0005580465076491237\n",
            "[Epoch:120] cost = 0.0006159194745123386\n",
            "[Epoch:121] cost = 0.0005726364906877279\n",
            "[Epoch:122] cost = 0.0007235787925310433\n",
            "[Epoch:123] cost = 0.0005609835498034954\n",
            "[Epoch:124] cost = 0.0005374561878852546\n",
            "[Epoch:125] cost = 0.0008464592974632978\n",
            "[Epoch:126] cost = 0.00047845602966845036\n",
            "[Epoch:127] cost = 0.0006039431900717318\n",
            "[Epoch:128] cost = 0.0005170522490516305\n",
            "[Epoch:129] cost = 0.0005459782551042736\n",
            "[Epoch:130] cost = 0.00047289973008446395\n",
            "[Epoch:131] cost = 0.0005131883081048727\n",
            "[Epoch:132] cost = 0.0005163436871953309\n",
            "[Epoch:133] cost = 0.0005473874625749886\n",
            "[Epoch:134] cost = 0.0005193345714360476\n",
            "[Epoch:135] cost = 0.0005709900287911296\n",
            "[Epoch:136] cost = 0.0005952101782895625\n",
            "[Epoch:137] cost = 0.0005429299199022353\n",
            "[Epoch:138] cost = 0.0005349908606149256\n",
            "[Epoch:139] cost = 0.0005197542486712337\n",
            "[Epoch:140] cost = 0.0006040853331796825\n",
            "[Epoch:141] cost = 0.0005545702879317105\n",
            "[Epoch:142] cost = 0.00047991875908337533\n",
            "[Epoch:143] cost = 0.0005134200910106301\n",
            "[Epoch:144] cost = 0.0005517001845873892\n",
            "[Epoch:145] cost = 0.0005841073580086231\n",
            "[Epoch:146] cost = 0.0004631680785678327\n",
            "[Epoch:147] cost = 0.0005043302662670612\n",
            "[Epoch:148] cost = 0.0004903280641883612\n",
            "[Epoch:149] cost = 0.0005345048266462982\n",
            "[Epoch:150] cost = 0.0005230286042205989\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_resnet34.state_dict(),\"/gdrive/MyDrive/data/model_ResNet34_150epoch.pth\")"
      ],
      "metadata": {
        "id": "0lyR1vLFVxkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestM_resnet34 = resnet34().to(device)\n",
        "TestM_resnet34.load_state_dict(torch.load('/gdrive/MyDrive/data/model_ResNet34_150epoch.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFuC6TZ1V7Ip",
        "outputId": "e1c477f5-66d8-4a93-f149-e14b430e9673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = TestM_resnet34(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        \n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the %d test images: %d %%' % (total,\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNt5vziP5nNt",
        "outputId": "dce60652-3d8c-47a7-f7a4-49575acea74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 624 test images: 75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DSuYQYCyVjRI"
      }
    }
  ]
}